# ffs_preprocessing

데이터 증강 -> 라벨링 -> scam / normal 데이터 합치고 -> 토큰화 후, 불용어가 등록되어있는 stopword 파일을 불러와서 불용어 처리 -> 나머지 단어들로 어휘 사전을 만들고
어휘 사전을 기준으로 숫자화(임베이딩) -> 유효한의미를 갖는 단어 500개를 데이터 셋에서 제외시킴 (패딩) -> 학습진행 
